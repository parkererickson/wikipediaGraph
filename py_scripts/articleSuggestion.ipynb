{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTigerGraph as tg\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import torch\n",
    "from py_scripts.gcn import GCN\n",
    "from py_scripts.gcn import threeLayerGCN\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import py_scripts.cfg as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 50\n",
    "wantedTopic = \"Saxophone\"\n",
    "unwantedTopic = \"Falkland_Islands\" #In future, determine automatically through the inverse of PageRank/other centrality algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tg.TigerGraphConnection(ipAddress=\"https://wikipediagraph.i.tgcloud.us\", apiToken=cfg.token, graphname=\"WikipediaGraph\") # connection to TigerGraph database\n",
    "\n",
    "articleToNum = {} # translation dictionary for article name to number (for dgl)\n",
    "numToArticle = {} # translation dictionary for number to article name\n",
    "i = 0\n",
    "def createEdgeList(result): # returns tuple of number version of edge\n",
    "    global i\n",
    "    if result[\"article1\"] in articleToNum:\n",
    "        fromKey = articleToNum[result[\"article1\"]]\n",
    "    else:\n",
    "        articleToNum[result[\"article1\"]] = i\n",
    "        numToArticle[i] = result[\"article1\"]\n",
    "        fromKey = i\n",
    "        i+=1\n",
    "    if result[\"article2\"] in articleToNum:\n",
    "        toKey = articleToNum[result[\"article2\"]]\n",
    "    else:\n",
    "        articleToNum[result[\"article2\"]] = i\n",
    "        numToArticle[i] = result[\"article2\"]\n",
    "        toKey = i\n",
    "        i+=1\n",
    "    return (fromKey, toKey)\n",
    "    \n",
    "edges = [createEdgeList(thing) for thing in  graph.runInstalledQuery(\"tupleArticle\", {})[\"results\"][0][\"list_of_article_tuples\"]] # creates list of edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "We have 4588 nodes.\nWe have 119881 edges.\n"
    }
   ],
   "source": [
    "wantedNum = articleToNum[wantedTopic]\n",
    "unwantedNum = articleToNum[unwantedTopic]\n",
    "\n",
    "g = nx.DiGraph()\n",
    "\n",
    "g.add_edges_from(edges)\n",
    "\n",
    "G = dgl.DGLGraph(g)\n",
    "\n",
    "print('We have %d nodes.' % G.number_of_nodes())\n",
    "print('We have %d edges.' % G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[0., 0., 1.,  ..., 0., 0., 0.]])\n"
    }
   ],
   "source": [
    "G.ndata[\"feat\"] = torch.eye(G.number_of_nodes()) # one hot encode nodes for features (replace with doc2vec in future)\n",
    "\n",
    "print(G.nodes[2].data['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = GCN(G.number_of_nodes(), 75, 2) #Two layer GCN\n",
    "net = threeLayerGCN(G.number_of_nodes(), 75, 25, 2)\n",
    "\n",
    "inputs = torch.eye(G.number_of_nodes())\n",
    "labeled_nodes = torch.tensor([wantedNum, unwantedNum])  # only the instructor and the president nodes are labeled\n",
    "labels = torch.tensor([0, 1])  # their labels are different\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 0 | Loss: 5.418e+00\nEpoch 1 | Loss: 1.775e+02\nEpoch 2 | Loss: 1.053e+02\nEpoch 3 | Loss: 3.666e+01\nEpoch 4 | Loss: 1.687e+00\nEpoch 5 | Loss: 6.866e-01\nEpoch 6 | Loss: 6.883e-01\n"
    }
   ],
   "source": [
    "all_logits = []\n",
    "for epoch in range(numEpochs):\n",
    "    logits = net(G, inputs)\n",
    "    # we save the logits for visualization later\n",
    "    all_logits.append(logits.detach())\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch %d | Loss: %6.3e' % (epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(all_logits[numEpochs-1])\n",
    "\n",
    "predictionsWithIndex = []\n",
    "a = 0\n",
    "for article in predictions:\n",
    "    predictionsWithIndex.append([a, article[0]])\n",
    "    a+=1\n",
    "\n",
    "predictionsWithIndex.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "topResults = predictionsWithIndex[:10]\n",
    "\n",
    "\n",
    "for article in topResults:\n",
    "    print(\"Article Id: \"+str(article[0]))\n",
    "    print(\"Article Name: \"+str(numToArticle[article[0]]))\n",
    "    print(\"Article Score: \"+str(article[1]))\n",
    "    print(\"\")"
   ]
  }
 ]
}